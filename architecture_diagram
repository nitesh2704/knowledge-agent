// Knowledge Base Agent Architecture
digraph {
	bgcolor="#0f1624" fontname=Arial fontsize=12 rankdir=TB
	node [fontname=Arial fontsize=11 style=filled]
	edge [color="#d3dde7" fontname=Arial fontsize=10]
	title [label="Knowledge Base Agent
RAG System Architecture" fillcolor="#ff6b4a" fontcolor=white fontsize=16 height=0.8 shape=box style="rounded,filled"]
	subgraph cluster_ui {
		color="#1e2735" fillcolor="#1e2735" fontcolor="#ff8d60" fontsize=13 label="User Interface Layer" style="filled,rounded"
		streamlit [label="Streamlit Web UI
(app.py)" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		upload [label="File Upload
(PDF/DOCX/TXT)" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		query [label="Question Input" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		display [label="Answer Display
+ Sources" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
	}
	subgraph cluster_core {
		color="#1e2735" fillcolor="#1e2735" fontcolor="#ff8d60" fontsize=13 label="Application Core" style="filled,rounded"
		ingest [label="Document Ingestion
(ingest.py)" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		chunk [label="Text Chunking
size=1200, overlap=80" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		query_proc [label="Query Processing
(query_knowledge_base)" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		retrieval [label="Semantic Retrieval
Top-K=5, threshold=0.8" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		prompt [label="Prompt Engineering
Context + Question" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
	}
	subgraph cluster_utils {
		color="#1e2735" fillcolor="#1e2735" fontcolor="#ff8d60" fontsize=13 label="Utility Functions (utils.py)" style="filled,rounded"
		parse [label="Document Parsers
pdfplumber, python-docx" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		embed_func [label="Embedding Function
gemini_embed()" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
		chat_func [label="Chat Function
gemini_chat()" fillcolor="#2d3a48" fontcolor="#f0f6fc" shape=box]
	}
	subgraph cluster_external {
		color="#1e2735" fillcolor="#1e2735" fontcolor="#ff8d60" fontsize=13 label="External Services" style="filled,rounded"
		gemini_embed [label="Gemini Embedding API
text-embedding-004
768 dimensions" fillcolor="#ff6b4a" fontcolor=white shape=box]
		gemini_llm [label="Gemini LLM API
gemini-2.0-flash
Answer Generation" fillcolor="#ff6b4a" fontcolor=white shape=box]
	}
	subgraph cluster_storage {
		color="#1e2735" fillcolor="#1e2735" fontcolor="#ff8d60" fontsize=13 label="Persistent Storage" style="filled,rounded"
		chromadb [label="ChromaDB
Vector Database
Cosine Similarity" fillcolor="#4da8ff" fontcolor=white shape=cylinder]
		metadata [label="Metadata Store
Chunk IDs, Sources" fillcolor="#4da8ff" fontcolor=white shape=cylinder]
	}
	config [label=".env Configuration
API Keys, Performance Tuning" fillcolor="#ffd700" fontcolor="#0f1624" fontsize=10 shape=note]
	title -> streamlit [style=invis]
	upload -> ingest [label="1. Upload
Document" fontcolor="#98b1c9"]
	ingest -> parse [label="2. Parse
Text" fontcolor="#98b1c9"]
	parse -> chunk [label="3. Split into
Chunks" fontcolor="#98b1c9"]
	chunk -> embed_func [label="4. Request
Embeddings" fontcolor="#98b1c9"]
	embed_func -> gemini_embed [label="5. API Call
(parallel)" fontcolor="#98b1c9"]
	gemini_embed -> embed_func [label="6. Vectors
(768-dim)" fontcolor="#98b1c9"]
	embed_func -> chromadb [label="7. Store
Vectors" fontcolor="#98b1c9"]
	chunk -> metadata [label="Store
Metadata" fontcolor="#98b1c9" style=dashed]
	query -> query_proc [label="1. User
Question" fontcolor="#98b1c9"]
	query_proc -> embed_func [label="2. Embed
Query" fontcolor="#98b1c9"]
	embed_func -> gemini_embed [label="3. Get Query
Vector" fontcolor="#98b1c9"]
	gemini_embed -> embed_func [label="4. Return
Vector" fontcolor="#98b1c9"]
	embed_func -> retrieval [label="5. Query
Vector" fontcolor="#98b1c9"]
	chromadb -> retrieval [label="6. Vector
Search" dir=back fontcolor="#98b1c9"]
	metadata -> retrieval [label="Fetch
Metadata" dir=back fontcolor="#98b1c9" style=dashed]
	retrieval -> prompt [label="7. Top-K
Chunks" fontcolor="#98b1c9"]
	prompt -> chat_func [label="8. Context +
Question" fontcolor="#98b1c9"]
	chat_func -> gemini_llm [label="9. Generate
Answer" fontcolor="#98b1c9"]
	gemini_llm -> chat_func [label="10. Response
Text" fontcolor="#98b1c9"]
	chat_func -> display [label="11. Render
Answer" fontcolor="#98b1c9"]
	config -> gemini_embed [color="#ffd700" style=dotted]
	config -> gemini_llm [color="#ffd700" style=dotted]
	config -> chunk [label="CHUNK_SIZE
EMBED_WORKERS" color="#ffd700" fontcolor="#ffd700" fontsize=9 style=dotted]
}
